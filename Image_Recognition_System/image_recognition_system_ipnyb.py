# -*- coding: utf-8 -*-
"""Image_Recognition_System.ipnyb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xdRsoRIY6i5eGHD3aafuSPA9clOfYkhb
"""



"""Importing dataset

"""

from google.colab import drive
drive.mount('/content/drive/')

"""Importing Libraries"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

"""# Data preprocessing

# Training image preprocessing
"""

training_set = tf.keras.utils.image_dataset_from_directory(
    '/content/drive/MyDrive/Images/Images',
    labels='inferred',
    label_mode='int',
    class_names=None,
    color_mode='rgb',
    batch_size=32,
    image_size=(64, 64),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation='bilinear',
    follow_links=False,
    crop_to_aspect_ratio=False
)

"""#Validation Image Preprocessing"""

validation_set = tf.keras.utils.image_dataset_from_directory(
    '/content/drive/MyDrive/Images/Images',
    labels='inferred',
    label_mode='int',
    class_names=None,
    color_mode='rgb',
    batch_size=32,
    image_size=(64, 64),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation='bilinear',
    follow_links=False,
    crop_to_aspect_ratio=False
)

"""#Model Building"""

cnn = tf.keras.models.Sequential()

"""#Building Convolution Layer"""

cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))
cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))

cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

# cnn.add(tf.keras.layers.Dropout(0.5)) # To avoid overfitting

cnn.add(tf.keras.layers.Flatten())

cnn.add(tf.keras.layers.Dense(units=512, activation='relu'))

cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))

cnn.add(tf.keras.layers.Dropout(0.5)) # Dropping some neuron to avoid overfitting

# Output Layer
cnn.add(tf.keras.layers.Dense(units=126, activation='softmax'))

"""# Compiling and Training Phase"""

cnn.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # Use from_logits=False since we're using softmax activation
    metrics=['accuracy']
)

cnn.summary()

# Train the model
training_history = cnn.fit(
    training_set,
    validation_data=validation_set,
    epochs=32
)

"""# Saving Model"""

cnn.save('trained_model.h5')

training_history.history  # Return Dictionary of History

# Recording History in Json file
import json
with open('training_history.json', 'w') as f:
    json.dump(training_history.history, f)

print(training_history.history.keys())

"""# Calculating Accuracy of Model Achieved on Validation Set"""

training_history.history['val_accuracy']

print("Validation set Accuracy: {} %".format(training_history.history['val_accuracy'][-2] * 100))

"""# Accuracy Visualization

# Training Visualization
"""

epochs = [i for i in range(1, 33)]
plt.plot(epochs, training_history.history['accuracy'], color = 'red', label='Training Accuracy')
plt.plot(epochs, training_history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Visualization of Training and Validation Accuracy Result')
plt.show()

plt.plot(epochs, training_history.history['val_accuracy'], color = 'green', label='Validation Accuracy')
plt.xlabel('Number of Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Visualization of Validation Accuracy Result')
plt.show

"""# Evaluating CNN Model"""

training_loss, training_accuracy = cnn.evaluate(training_set)

val_loss, val_accuracy = cnn.evaluate(validation_set)

"""# Test Set Evaluation"""

test_set = tf.keras.utils.image_dataset_from_directory(
    '/content/drive/MyDrive/Images/Images',
    labels='inferred',
    label_mode='int',
    class_names=None,
    color_mode='rgb',
    batch_size=32,
    image_size=(64, 64),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation='bilinear',
    follow_links=False,
    crop_to_aspect_ratio=False
)

test_loss, test_accuracy = cnn.evaluate(test_set)

test_accuracy